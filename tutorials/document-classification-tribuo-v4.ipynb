{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "This tutorial will show how to perform document classification in Tribuo, using a variety of different methods to extract features from the text. We'll use the venerable [20-newsgroups dataset](http://qwone.com/~jason/20Newsgroups/) where the task is to predict what newsgroup a particular post is from, though this tutorial would be equally applicable to any document classification task (including tasks like sentiment analysis).\n",
    "\n",
    "# Setup\n",
    "\n",
    "You'll need a copy of the 20 newsgroups dataset, so first download and unpack it:\n",
    "\n",
    "```\n",
    "wget http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\n",
    "mkdir 20news\n",
    "cd 20news\n",
    "tar -zxf ../20news-bydate.tar.gz\n",
    "```\n",
    "\n",
    "This leaves you with two directories `20news-bydate-train` and `20news-bydate-test`, which contain the standard train and test split for this data.\n",
    "\n",
    "20 newsgroups comes in a fairly standard format, the dataset is represented by a set of directories where the directory name is the class label, and the directory contains a collection of documents with one document in each file. Each file is a single Usenet post. For the purposes of this tutorial, we'll use the subject and body of the post as the input text for classification.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```\n",
    "$ ls 20news-bydate-train/\n",
    "alt.atheism/               comp.sys.mac.hardware/  rec.motorcycles/     sci.electronics/         talk.politics.guns/\n",
    "comp.graphics/             comp.windows.x/         rec.sport.baseball/  sci.med/                 talk.politics.mideast/\n",
    "comp.os.ms-windows.misc/   misc.forsale/           rec.sport.hockey/    sci.space/               talk.politics.misc/\n",
    "comp.sys.ibm.pc.hardware/  rec.autos/              sci.crypt/           soc.religion.christian/  talk.religion.misc/\n",
    "$ ls 20news-bydate-train/comp.graphics/\n",
    "37261  37949  38233  38270  38305  38344  38381  38417  38454  38489  38525  38562  38598  38633  38668  38703  38739\n",
    "37913  37950  38234  38271  38306  38346  38382  38418  38455  38490  38526  38563  38599  38634  38669  38704  38740\n",
    "37914  37951  38235  38272  38307  38347  38383  38420  38456  38491  38527  38564  38600  38635  38670  38705  38741\n",
    "37915  37952  38236  38273  38308  38348  38384  38421  38457  38492  38528  38565  38601  38636  38671  38706  38742\n",
    "...\n",
    "```\n",
    "\n",
    "As this is a pretty common format, Tribuo has a specific `DataSource` which can be used to read in this sort of data, `org.tribuo.data.text.DirectoryFileSource`.\n",
    "\n",
    "We're going to use the classification experiments jar, along with the ONNX jar which provides support for loading in contextual word embedding models like [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jars ./tribuo-classification-experiments-4.1.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ./tribuo-onnx-4.1.0-SNAPSHOT-jar-with-dependencies.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need a selection of imports from the `org.tribuo.data.text` package, along with the usual imports from `org.tribuo` and `org.tribuo.classification` we use when working with classification tasks. We'll load in the BERT support from the `org.tribuo.interop.onnx.extractors` package. Tribuo's BERT support loads in models and tokenizers from [HuggingFace's Transformer](https://huggingface.co/transformers/) package, and can be easily extended to support non-BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.Paths;\n",
    "import com.oracle.labs.mlrg.olcut.util.Pair;\n",
    "import org.tribuo.*;\n",
    "import org.tribuo.data.text.*;\n",
    "import org.tribuo.data.text.impl.*;\n",
    "import org.tribuo.classification.*;\n",
    "import org.tribuo.classification.evaluation.*;\n",
    "import org.tribuo.classification.sgd.linear.LogisticRegressionTrainer;\n",
    "import org.tribuo.interop.onnx.extractors.BERTFeatureExtractor;\n",
    "import org.tribuo.util.tokens.universal.UniversalTokenizer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll instantiate a few classes that we'll use throughout this tutorial, the label factory, the evaluator and the paths to the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var labelFactory = new LabelFactory();\n",
    "var labelEvaluator = new LabelEvaluator();\n",
    "var trainPath = Paths.get(\"./20-news/20news-bydate-train\");\n",
    "var testPath = Paths.get(\"./20-news/20news-bydate-test\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from text\n",
    "Much of the work of machine learning is in presenting an appropriate representation of the data to the model. This is especially true when working with text data, as there is a plethora of approaches for converting text into the numbers that ML algorithms operate on. The `DirectoryFileSource` allows the user to choose the feature extraction, as it requires a `TextFeatureExtractor` which converts the `String` representing the input text into a Tribuo `Example`. We'll cover several different implementations of the `TextFeatureExtractor` interface in this tutorial, and we expect that users will implement it in their own classes to cope with specific feature extraction requirements.\n",
    "\n",
    "We'll start with the simplest approach, a \"bag of words\", where each document is represented by the counts of the words in that document. This means the feature space is equal to the number of words, and most documents only have a positive value for a small number of words (as most words don't appear in any given document). This is particularly well suited to Tribuo's sparse vector representation of examples, and this suitability for NLP tasks is the reason that Tribuo is designed this way. Of course, first we'll need to tell the extractor what a word is, and for this we use a `Tokenizer`. Tokenizers split up a `String` into a stream of tokens. Tribuo provides several basic tokenizers, and an interface for tokenization. We're going to use Tribuo's `UniversalTokenizer` which is descended from tokenizers developed at Sun Labs in the 90s, and used in a variety of Sun products since that time. Once we've got tokens, we'll build a `TokenPipeline` which can convert `String`s into features, and then pass that to the basic `TextFeatureExtractor` implementation, helpfully called `TextFeatureExtractorImpl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var tokenizer = new UniversalTokenizer();\n",
    "var unigramPipeline = new TokenPipeline(tokenizer, 1, true);\n",
    "var unigramExtractor = new TextFeatureExtractorImpl<Label>(unigramPipeline);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now almost ready to make our train and test data sources, and load in the data. The `DirectoryFileSource` also accepts an array of `DocumentPreprocessor`s which can be used to transform the text before feature extraction takes place. We're going to use a specific preprocessor which standardises the 20 newsgroups data by stripping out the mail headers and returning only the subject and the body of the email. In general the preprocessors are dataset and task specific, which is why Tribuo doesn't ship with many implementations as in most cases users will need to write one from scratch for their specific task. We'll pass in an instance of the `NewsPreprocessor` and construct our data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var newsProc = new NewsPreprocessor();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a helper function to load the data sources and create the datasets. We're also going to restrict the test dataset so it only contains valid examples, as 20 newsgroups has some test examples that share no words with the train examples (and so have no features we could use to make predictions with).\n",
    "\n",
    "Let's check our datasets and see if everything has loaded in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram training data size = 11314, number of features = 146037, number of classes = 20\n",
      "unigram testing data size = 7531, number of features = 146037, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "public Pair<Dataset<Label>,Dataset<Label>> mkDatasets(String name, TextFeatureExtractor<Label> extractor) {\n",
    "    var trainSource = new DirectoryFileSource<>(trainPath,labelFactory,extractor,newsProc);\n",
    "    var testSource = new DirectoryFileSource<>(testPath,labelFactory,extractor,newsProc);\n",
    "    var trainDS = new MutableDataset<>(trainSource);\n",
    "    var testDS = new ImmutableDataset<>(testSource,trainDS.getFeatureIDMap(),trainDS.getOutputIDInfo(),true);\n",
    "    System.out.println(String.format(name + \" training data size = %d, number of features = %d, number of classes = %d\",trainDS.size(),trainDS.getFeatureMap().size(),trainDS.getOutputInfo().size()));\n",
    "    System.out.println(String.format(name + \" testing data size = %d, number of features = %d, number of classes = %d\",testDS.size(),testDS.getFeatureMap().size(),testDS.getOutputInfo().size()));\n",
    "    return new Pair<>(trainDS,testDS);\n",
    "}\n",
    "\n",
    "var unigramPair = mkDatasets(\"unigram\",unigramExtractor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded in 11,314 training documents containing 146,037 unique words and 7,532 test documents, each with the expected 20 classes.\n",
    "\n",
    "Now we're ready to train a model. Let's start with a simple logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                n          tp          fn          fp      recall        prec          f1\n",
      "soc.religion.christian             398         314          84         131       0.789       0.706       0.745\n",
      "rec.autos                          396         305          91          80       0.770       0.792       0.781\n",
      "talk.religion.misc                 251         147         104         146       0.586       0.502       0.540\n",
      "comp.windows.x                     394         306          88         106       0.777       0.743       0.759\n",
      "rec.sport.baseball                 397         322          75          63       0.811       0.836       0.824\n",
      "comp.graphics                      389         258         131         127       0.663       0.670       0.667\n",
      "talk.politics.mideast              376         287          89          46       0.763       0.862       0.810\n",
      "comp.sys.ibm.pc.hardware           392         253         139         183       0.645       0.580       0.611\n",
      "sci.med                            396         259         137          73       0.654       0.780       0.712\n",
      "comp.os.ms-windows.misc            394         245         149         107       0.622       0.696       0.657\n",
      "sci.crypt                          396         326          70          60       0.823       0.845       0.834\n",
      "comp.sys.mac.hardware              385         257         128          86       0.668       0.749       0.706\n",
      "misc.forsale                       390         329          61          94       0.844       0.778       0.809\n",
      "rec.motorcycles                    398         352          46          66       0.884       0.842       0.863\n",
      "talk.politics.misc                 310         171         139         105       0.552       0.620       0.584\n",
      "sci.electronics                    393         265         128         142       0.674       0.651       0.663\n",
      "rec.sport.hockey                   399         349          50          42       0.875       0.893       0.884\n",
      "sci.space                          394         321          73          45       0.815       0.877       0.845\n",
      "alt.atheism                        319         233          86         102       0.730       0.696       0.713\n",
      "talk.politics.guns                 364         292          72         136       0.802       0.682       0.737\n",
      "Total                            7,531       5,591       1,940       1,940\n",
      "Accuracy                                                                         0.742\n",
      "Micro Average                                                                    0.742       0.742       0.742\n",
      "Macro Average                                                                    0.737       0.740       0.737\n",
      "Balanced Error Rate                                                              0.263\n"
     ]
    }
   ],
   "source": [
    "var lrTrainer = new LogisticRegressionTrainer();\n",
    "var unigramModel = lrTrainer.train(unigramPair.getA());\n",
    "var unigramEval = labelEvaluator.evaluate(unigramModel,unigramPair.getB());\n",
    "System.out.println(unigramEval);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the logistic regression trained on unigrams gets about 74% accuracy.\n",
    "\n",
    "Let's try a little more complicated feature extractor. The natural step from unigrams is to include word pairs (or bigrams) and count the occurrence of those. This allows us to get simple negations (e.g., \"not bad\" rather than \"not\" and \"bad\") along with places like \"New York\" rather than \"new\" and \"york\". In Tribuo this is as straightforward as telling the token pipeline we'd like bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram training data size = 11314, number of features = 1253665, number of classes = 20\n",
      "bigram testing data size = 7531, number of features = 1253665, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "var bigramPipeline = new TokenPipeline(tokenizer, 2, true);\n",
    "var bigramExtractor = new TextFeatureExtractorImpl<Label>(bigramPipeline);\n",
    "var bigramPair = mkDatasets(\"bigram\",bigramExtractor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the feature space has massively increased due to the presence of bigram features, we've now got 1.2 million features from the same 11,314 documents.\n",
    "\n",
    "Now to train another logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                n          tp          fn          fp      recall        prec          f1\n",
      "soc.religion.christian             398         337          61         110       0.847       0.754       0.798\n",
      "rec.autos                          396         315          81          99       0.795       0.761       0.778\n",
      "talk.religion.misc                 251         144         107         110       0.574       0.567       0.570\n",
      "comp.windows.x                     394         287         107          88       0.728       0.765       0.746\n",
      "rec.sport.baseball                 397         327          70          58       0.824       0.849       0.836\n",
      "comp.graphics                      389         218         171         108       0.560       0.669       0.610\n",
      "talk.politics.mideast              376         311          65          54       0.827       0.852       0.839\n",
      "comp.sys.ibm.pc.hardware           392         264         128         199       0.673       0.570       0.618\n",
      "sci.med                            396         287         109          80       0.725       0.782       0.752\n",
      "comp.os.ms-windows.misc            394         239         155         131       0.607       0.646       0.626\n",
      "sci.crypt                          396         334          62          64       0.843       0.839       0.841\n",
      "comp.sys.mac.hardware              385         251         134         100       0.652       0.715       0.682\n",
      "misc.forsale                       390         337          53          99       0.864       0.773       0.816\n",
      "rec.motorcycles                    398         342          56          48       0.859       0.877       0.868\n",
      "talk.politics.misc                 310         172         138          80       0.555       0.683       0.612\n",
      "sci.electronics                    393         239         154         104       0.608       0.697       0.649\n",
      "rec.sport.hockey                   399         348          51          37       0.872       0.904       0.888\n",
      "sci.space                          394         335          59         117       0.850       0.741       0.792\n",
      "alt.atheism                        319         226          93          88       0.708       0.720       0.714\n",
      "talk.politics.guns                 364         296          68         148       0.813       0.667       0.733\n",
      "Total                            7,531       5,609       1,922       1,922\n",
      "Accuracy                                                                         0.745\n",
      "Micro Average                                                                    0.745       0.745       0.745\n",
      "Macro Average                                                                    0.739       0.742       0.738\n",
      "Balanced Error Rate                                                              0.261\n"
     ]
    }
   ],
   "source": [
    "var bigramModel = lrTrainer.train(bigramPair.getA());\n",
    "var bigramEval = labelEvaluator.evaluate(bigramModel,bigramPair.getB());\n",
    "System.out.println(bigramEval);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our performance only improved a little bit, from 74.2% to 74.5%. This is because despite there being more information in the features, there are also many, many more features making it easier to confuse this simple linear model. As we increase the number of n-gram features we'll start to see diminishing returns as the model complexity increases without a commensurate increase in training data.\n",
    "\n",
    "One popular technique for reducing the feature space when dealing with such large problems is feature hashing. This is where the features are mapped back down to a smaller space using a hash function. It induces collisions between the features, so the model might treat \"New York\" and \"San Fransisco\" as the same feature, but the collisions are generated essentially at random based on the hash function, and so provide a strong regularising effect which frequently improves performance.\n",
    "\n",
    "To use feature hashing in Tribuo simply pass a hash dimension to the `TokenPipeline` on construction. We'll map everything down to 50,000 features and see how that affects the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash-50k training data size = 11314, number of features = 50000, number of classes = 20\n",
      "hash-50k testing data size = 7532, number of features = 50000, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "var hashPipeline = new TokenPipeline(tokenizer, 2, true, 50000);\n",
    "var hashExtractor = new TextFeatureExtractorImpl<Label>(hashPipeline);\n",
    "var hashPair = mkDatasets(\"hash-50k\",hashExtractor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we have the same number of training & test examples, but now there are only 50,000 features. Let's build another logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                n          tp          fn          fp      recall        prec          f1\n",
      "soc.religion.christian             398         319          79         105       0.802       0.752       0.776\n",
      "rec.autos                          396         282         114          76       0.712       0.788       0.748\n",
      "talk.religion.misc                 251         135         116         128       0.538       0.513       0.525\n",
      "comp.windows.x                     395         276         119          98       0.699       0.738       0.718\n",
      "rec.sport.baseball                 397         333          64          97       0.839       0.774       0.805\n",
      "comp.graphics                      389         211         178         119       0.542       0.639       0.587\n",
      "talk.politics.mideast              376         261         115          30       0.694       0.897       0.783\n",
      "comp.sys.ibm.pc.hardware           392         244         148         201       0.622       0.548       0.583\n",
      "sci.med                            396         234         162          97       0.591       0.707       0.644\n",
      "comp.os.ms-windows.misc            394         234         160         175       0.594       0.572       0.583\n",
      "sci.crypt                          396         326          70          85       0.823       0.793       0.808\n",
      "comp.sys.mac.hardware              385         251         134         133       0.652       0.654       0.653\n",
      "misc.forsale                       390         313          77         111       0.803       0.738       0.769\n",
      "rec.motorcycles                    398         317          81          67       0.796       0.826       0.811\n",
      "talk.politics.misc                 310         167         143         120       0.539       0.582       0.559\n",
      "sci.electronics                    393         221         172         146       0.562       0.602       0.582\n",
      "rec.sport.hockey                   399         337          62          48       0.845       0.875       0.860\n",
      "sci.space                          394         326          68         110       0.827       0.748       0.786\n",
      "alt.atheism                        319         228          91         130       0.715       0.637       0.674\n",
      "talk.politics.guns                 364         284          80         157       0.780       0.644       0.706\n",
      "Total                            7,532       5,299       2,233       2,233\n",
      "Accuracy                                                                         0.704\n",
      "Micro Average                                                                    0.704       0.704       0.704\n",
      "Macro Average                                                                    0.699       0.701       0.698\n",
      "Balanced Error Rate                                                              0.301\n"
     ]
    }
   ],
   "source": [
    "var hashModel = lrTrainer.train(hashPair.getA());\n",
    "var hashEval = labelEvaluator.evaluate(hashModel,hashPair.getB());\n",
    "System.out.println(hashEval);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- discuss word embeddings\n",
    "- BERT CLS\n",
    "- BERT CLS + Average token embeddings\n",
    "- Provenance and big models (i.e. BERT needs to be on disk, it's not in your model), the feature extractor is provenance not an object.\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.9.1+1-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
